{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T12:19:06.455295Z",
     "start_time": "2025-12-07T12:19:02.335879Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import umap\n",
    "\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "from scipy import  ndimage\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "from jb3 import nasdaq"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data prepare",
   "id": "4bb525c8fd735225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:38:15.358071Z",
     "start_time": "2025-12-07T12:38:14.666187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sc = nasdaq.get_nasdaq_screener(limit=500,country=\"United States\", sector=\"Health care\")\n",
    "sc.to_csv(\"sc.csv\", index=False)\n",
    "sc = pd.read_csv(\"sc.csv\")\n",
    "sc"
   ],
   "id": "f78334430d1dc29e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    symbol                                               name   lastsale  \\\n",
       "0      LLY                 Eli Lilly and Company Common Stock  $1,010.31   \n",
       "1      JNJ                     Johnson & Johnson Common Stock    $201.93   \n",
       "2     ABBV                           AbbVie Inc. Common Stock    $226.08   \n",
       "3      UNH  UnitedHealth Group Incorporated Common Stock (DE)    $330.91   \n",
       "4      MRK           Merck & Company, Inc. Common Stock (new)     $99.72   \n",
       "..     ...                                                ...        ...   \n",
       "495    IRD                   Opus Genetics, Inc. Common Stock      $2.27   \n",
       "496  RVMDW                 Revolution Medicines, Inc. Warrant    $0.8011   \n",
       "497   SAVA                Cassava Sciences, Inc. Common Stock      $3.19   \n",
       "498   CGTX          Cognition Therapeutics, Inc. Common Stock      $1.73   \n",
       "499    NBY         NovaBay Pharmaceuticals, Inc. Common Stock      $1.21   \n",
       "\n",
       "    netchange pctchange        marketCap                            url  \n",
       "0       -4.18   -0.412%  955,130,663,535    /market-activity/stocks/lly  \n",
       "1       -0.55   -0.272%  486,508,959,947    /market-activity/stocks/jnj  \n",
       "2       -2.63    -1.15%  399,570,317,603   /market-activity/stocks/abbv  \n",
       "3       -2.58   -0.774%  299,751,057,744    /market-activity/stocks/unh  \n",
       "4       -1.17    -1.16%  247,507,287,290    /market-activity/stocks/mrk  \n",
       "..        ...       ...              ...                            ...  \n",
       "495      0.04    1.794%      156,548,752    /market-activity/stocks/ird  \n",
       "496    0.0011    0.138%      154,868,496  /market-activity/stocks/rvmdw  \n",
       "497     -0.13   -3.916%      154,102,188   /market-activity/stocks/sava  \n",
       "498     -0.03   -1.705%      152,714,466   /market-activity/stocks/cgtx  \n",
       "499      0.12   11.009%      152,473,006    /market-activity/stocks/nby  \n",
       "\n",
       "[500 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>lastsale</th>\n",
       "      <th>netchange</th>\n",
       "      <th>pctchange</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLY</td>\n",
       "      <td>Eli Lilly and Company Common Stock</td>\n",
       "      <td>$1,010.31</td>\n",
       "      <td>-4.18</td>\n",
       "      <td>-0.412%</td>\n",
       "      <td>955,130,663,535</td>\n",
       "      <td>/market-activity/stocks/lly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>Johnson &amp; Johnson Common Stock</td>\n",
       "      <td>$201.93</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.272%</td>\n",
       "      <td>486,508,959,947</td>\n",
       "      <td>/market-activity/stocks/jnj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc. Common Stock</td>\n",
       "      <td>$226.08</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>-1.15%</td>\n",
       "      <td>399,570,317,603</td>\n",
       "      <td>/market-activity/stocks/abbv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNH</td>\n",
       "      <td>UnitedHealth Group Incorporated Common Stock (DE)</td>\n",
       "      <td>$330.91</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>-0.774%</td>\n",
       "      <td>299,751,057,744</td>\n",
       "      <td>/market-activity/stocks/unh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MRK</td>\n",
       "      <td>Merck &amp; Company, Inc. Common Stock (new)</td>\n",
       "      <td>$99.72</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.16%</td>\n",
       "      <td>247,507,287,290</td>\n",
       "      <td>/market-activity/stocks/mrk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>IRD</td>\n",
       "      <td>Opus Genetics, Inc. Common Stock</td>\n",
       "      <td>$2.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.794%</td>\n",
       "      <td>156,548,752</td>\n",
       "      <td>/market-activity/stocks/ird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>RVMDW</td>\n",
       "      <td>Revolution Medicines, Inc. Warrant</td>\n",
       "      <td>$0.8011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.138%</td>\n",
       "      <td>154,868,496</td>\n",
       "      <td>/market-activity/stocks/rvmdw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>SAVA</td>\n",
       "      <td>Cassava Sciences, Inc. Common Stock</td>\n",
       "      <td>$3.19</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-3.916%</td>\n",
       "      <td>154,102,188</td>\n",
       "      <td>/market-activity/stocks/sava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>CGTX</td>\n",
       "      <td>Cognition Therapeutics, Inc. Common Stock</td>\n",
       "      <td>$1.73</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-1.705%</td>\n",
       "      <td>152,714,466</td>\n",
       "      <td>/market-activity/stocks/cgtx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>NBY</td>\n",
       "      <td>NovaBay Pharmaceuticals, Inc. Common Stock</td>\n",
       "      <td>$1.21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>11.009%</td>\n",
       "      <td>152,473,006</td>\n",
       "      <td>/market-activity/stocks/nby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = nasdaq.download_ticker_data(sc.symbol.tolist(), pivot_col=\"close\", clean=True)",
   "id": "95302d8ca07ec11a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv(\"CG-data.csv\", index=True)",
   "id": "cb399d7dc1ca8b16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:06:28.133546Z",
     "start_time": "2025-12-07T12:06:28.017878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"CG-data.csv\", parse_dates=True, index_col = 0)\n",
    "df"
   ],
   "id": "b4835e72cc681d1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            AARD    ABBV    ABEO  ABSI     ABT   ACAD   ACHC       ACHV  \\\n",
       "date                                                                      \n",
       "2015-11-30   NaN   58.15  116.25   NaN   44.92  37.95  69.01  5675.9432   \n",
       "2015-12-01   NaN   59.02  111.75   NaN   45.46  37.51  69.34  5763.9424   \n",
       "2015-12-02   NaN   57.72  104.50   NaN   45.22  37.48  69.21  3585.9641   \n",
       "2015-12-03   NaN   56.12  101.50   NaN   44.15  35.24  66.13  3101.9690   \n",
       "2015-12-04   NaN   57.18  101.25   NaN   45.30  36.15  67.62  2661.9734   \n",
       "...          ...     ...     ...   ...     ...    ...    ...        ...   \n",
       "2025-11-21  9.37  236.28    4.48  2.93  128.11  23.56  15.18     3.9600   \n",
       "2025-11-24  9.50  229.51    4.59  2.96  127.19  23.90  15.54     3.9700   \n",
       "2025-11-25  9.37  231.80    4.88  3.07  128.05  24.39  16.57     4.5900   \n",
       "2025-11-26  9.67  227.66    5.15  3.09  128.54  24.81  17.15     4.8400   \n",
       "2025-11-28  9.98  227.70    5.07  3.17  128.90  25.04  17.20     4.8700   \n",
       "\n",
       "             ACLX   ACRS  ...    XOMA    XOMAO  XOMAP   XRAY   YDES       ZBH  \\\n",
       "date                      ...                                                   \n",
       "2015-11-30    NaN  23.55  ...  26.600      NaN    NaN  60.66    NaN   99.0881   \n",
       "2015-12-01    NaN  23.24  ...  29.200      NaN    NaN  61.97    NaN  100.7656   \n",
       "2015-12-02    NaN  21.40  ...  28.000      NaN    NaN  62.44    NaN  100.3143   \n",
       "2015-12-03    NaN  20.55  ...  27.600      NaN    NaN  62.61    NaN   97.4695   \n",
       "2015-12-04    NaN  21.13  ...  27.200      NaN    NaN  63.08    NaN   98.6369   \n",
       "...           ...    ...  ...     ...      ...    ...    ...    ...       ...   \n",
       "2025-11-21  90.19   2.51  ...  31.750  25.4100  26.56  10.58   8.45   92.1800   \n",
       "2025-11-24  74.96   2.75  ...  31.800  25.4400  26.49  10.73   8.83   93.5200   \n",
       "2025-11-25  73.00   2.73  ...  31.845  25.3900  26.49  11.09   9.29   97.0700   \n",
       "2025-11-26  73.25   2.88  ...  32.290  25.4199  26.62  11.29  10.52   97.5500   \n",
       "2025-11-28  72.71   2.83  ...  32.130  25.4700  26.62  11.34  11.53   97.5200   \n",
       "\n",
       "             ZBIO     ZTS    ZVRA   ZYME  \n",
       "date                                      \n",
       "2015-11-30    NaN   46.70  277.12    NaN  \n",
       "2015-12-01    NaN   47.01  268.64    NaN  \n",
       "2015-12-02    NaN   46.37  266.88    NaN  \n",
       "2015-12-03    NaN   45.20  277.44    NaN  \n",
       "2015-12-04    NaN   46.46  271.36    NaN  \n",
       "...           ...     ...     ...    ...  \n",
       "2025-11-21  35.80  122.06    8.60  24.02  \n",
       "2025-11-24  38.25  122.87    8.65  24.99  \n",
       "2025-11-25  39.86  127.89    8.40  26.18  \n",
       "2025-11-26  40.53  127.69    8.60  27.33  \n",
       "2025-11-28  38.83  128.18    8.43  26.71  \n",
       "\n",
       "[2515 rows x 500 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AARD</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABEO</th>\n",
       "      <th>ABSI</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACAD</th>\n",
       "      <th>ACHC</th>\n",
       "      <th>ACHV</th>\n",
       "      <th>ACLX</th>\n",
       "      <th>ACRS</th>\n",
       "      <th>...</th>\n",
       "      <th>XOMA</th>\n",
       "      <th>XOMAO</th>\n",
       "      <th>XOMAP</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>YDES</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBIO</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZVRA</th>\n",
       "      <th>ZYME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.15</td>\n",
       "      <td>116.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.92</td>\n",
       "      <td>37.95</td>\n",
       "      <td>69.01</td>\n",
       "      <td>5675.9432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.55</td>\n",
       "      <td>...</td>\n",
       "      <td>26.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.70</td>\n",
       "      <td>277.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59.02</td>\n",
       "      <td>111.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.46</td>\n",
       "      <td>37.51</td>\n",
       "      <td>69.34</td>\n",
       "      <td>5763.9424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.24</td>\n",
       "      <td>...</td>\n",
       "      <td>29.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.7656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.01</td>\n",
       "      <td>268.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57.72</td>\n",
       "      <td>104.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.22</td>\n",
       "      <td>37.48</td>\n",
       "      <td>69.21</td>\n",
       "      <td>3585.9641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.40</td>\n",
       "      <td>...</td>\n",
       "      <td>28.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.3143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.37</td>\n",
       "      <td>266.88</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>56.12</td>\n",
       "      <td>101.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.15</td>\n",
       "      <td>35.24</td>\n",
       "      <td>66.13</td>\n",
       "      <td>3101.9690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.55</td>\n",
       "      <td>...</td>\n",
       "      <td>27.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.4695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.20</td>\n",
       "      <td>277.44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>57.18</td>\n",
       "      <td>101.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.30</td>\n",
       "      <td>36.15</td>\n",
       "      <td>67.62</td>\n",
       "      <td>2661.9734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.13</td>\n",
       "      <td>...</td>\n",
       "      <td>27.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.6369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.46</td>\n",
       "      <td>271.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-21</th>\n",
       "      <td>9.37</td>\n",
       "      <td>236.28</td>\n",
       "      <td>4.48</td>\n",
       "      <td>2.93</td>\n",
       "      <td>128.11</td>\n",
       "      <td>23.56</td>\n",
       "      <td>15.18</td>\n",
       "      <td>3.9600</td>\n",
       "      <td>90.19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>...</td>\n",
       "      <td>31.750</td>\n",
       "      <td>25.4100</td>\n",
       "      <td>26.56</td>\n",
       "      <td>10.58</td>\n",
       "      <td>8.45</td>\n",
       "      <td>92.1800</td>\n",
       "      <td>35.80</td>\n",
       "      <td>122.06</td>\n",
       "      <td>8.60</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-24</th>\n",
       "      <td>9.50</td>\n",
       "      <td>229.51</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.96</td>\n",
       "      <td>127.19</td>\n",
       "      <td>23.90</td>\n",
       "      <td>15.54</td>\n",
       "      <td>3.9700</td>\n",
       "      <td>74.96</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>31.800</td>\n",
       "      <td>25.4400</td>\n",
       "      <td>26.49</td>\n",
       "      <td>10.73</td>\n",
       "      <td>8.83</td>\n",
       "      <td>93.5200</td>\n",
       "      <td>38.25</td>\n",
       "      <td>122.87</td>\n",
       "      <td>8.65</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-25</th>\n",
       "      <td>9.37</td>\n",
       "      <td>231.80</td>\n",
       "      <td>4.88</td>\n",
       "      <td>3.07</td>\n",
       "      <td>128.05</td>\n",
       "      <td>24.39</td>\n",
       "      <td>16.57</td>\n",
       "      <td>4.5900</td>\n",
       "      <td>73.00</td>\n",
       "      <td>2.73</td>\n",
       "      <td>...</td>\n",
       "      <td>31.845</td>\n",
       "      <td>25.3900</td>\n",
       "      <td>26.49</td>\n",
       "      <td>11.09</td>\n",
       "      <td>9.29</td>\n",
       "      <td>97.0700</td>\n",
       "      <td>39.86</td>\n",
       "      <td>127.89</td>\n",
       "      <td>8.40</td>\n",
       "      <td>26.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-26</th>\n",
       "      <td>9.67</td>\n",
       "      <td>227.66</td>\n",
       "      <td>5.15</td>\n",
       "      <td>3.09</td>\n",
       "      <td>128.54</td>\n",
       "      <td>24.81</td>\n",
       "      <td>17.15</td>\n",
       "      <td>4.8400</td>\n",
       "      <td>73.25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>...</td>\n",
       "      <td>32.290</td>\n",
       "      <td>25.4199</td>\n",
       "      <td>26.62</td>\n",
       "      <td>11.29</td>\n",
       "      <td>10.52</td>\n",
       "      <td>97.5500</td>\n",
       "      <td>40.53</td>\n",
       "      <td>127.69</td>\n",
       "      <td>8.60</td>\n",
       "      <td>27.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-28</th>\n",
       "      <td>9.98</td>\n",
       "      <td>227.70</td>\n",
       "      <td>5.07</td>\n",
       "      <td>3.17</td>\n",
       "      <td>128.90</td>\n",
       "      <td>25.04</td>\n",
       "      <td>17.20</td>\n",
       "      <td>4.8700</td>\n",
       "      <td>72.71</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>32.130</td>\n",
       "      <td>25.4700</td>\n",
       "      <td>26.62</td>\n",
       "      <td>11.34</td>\n",
       "      <td>11.53</td>\n",
       "      <td>97.5200</td>\n",
       "      <td>38.83</td>\n",
       "      <td>128.18</td>\n",
       "      <td>8.43</td>\n",
       "      <td>26.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 500 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:06:32.212441Z",
     "start_time": "2025-12-07T12:06:32.181098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_2020 = df[df.index.year == 2020]\n",
    "df_2021 = df[df.index.year == 2021]\n",
    "df_2022 = df[df.index.year == 2022]\n",
    "df_2023 = df[df.index.year == 2023]\n",
    "df_2024 = df[df.index.year == 2024]\n",
    "df_2025 = df[df.index.year == 2025]\n",
    "\n",
    "# --- Odstranimo stolpce z NaN ---\n",
    "df_2020 = df_2020.drop(columns=df_2020.columns[df_2020.isna().any()], errors=\"ignore\")\n",
    "df_2021 = df_2021.drop(columns=df_2021.columns[df_2021.isna().any()], errors=\"ignore\")\n",
    "df_2022 = df_2022.drop(columns=df_2022.columns[df_2022.isna().any()], errors=\"ignore\")\n",
    "df_2023 = df_2023.drop(columns=df_2023.columns[df_2023.isna().any()], errors=\"ignore\")\n",
    "df_2024 = df_2024.drop(columns=df_2024.columns[df_2024.isna().any()], errors=\"ignore\")\n",
    "df_2025 = df_2025.drop(columns=df_2025.columns[df_2025.isna().any()], errors=\"ignore\")\n",
    "\n",
    "df_full = df[df.index.year >= 2020].drop(columns=df.columns[df.isna().any()], errors=\"ignore\")\n"
   ],
   "id": "8c0d2b2a5c90c9c5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:06:34.480586Z",
     "start_time": "2025-12-07T12:06:34.395323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def preprocess_prices(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # detrending\n",
    "    df_detr = df - df.rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "    # standard scaling\n",
    "    df_scaled = (df_detr - df_detr.mean()) / df_detr.std()\n",
    "\n",
    "    # odstrani stolpce z NaN\n",
    "    df_scaled = df_scaled.dropna(axis=1)\n",
    "\n",
    "    return df_scaled\n",
    "\n",
    "\n",
    "df_2020_scaled = preprocess_prices(df_2020)\n",
    "df_2021_scaled = preprocess_prices(df_2021)\n",
    "df_2022_scaled = preprocess_prices(df_2022)\n",
    "df_2023_scaled = preprocess_prices(df_2023)\n",
    "df_2024_scaled = preprocess_prices(df_2024)\n",
    "df_2025_scaled = preprocess_prices(df_2025)\n",
    "\n",
    "df_full_scaled = preprocess_prices(df[df.index.year >= 2020])\n",
    "\n",
    "print(\n",
    "    f\"shape(df_2020) = {df_2020.shape},    log = {df_2020_scaled.shape}\\n\"\n",
    "    f\"shape(df_2021) = {df_2021.shape},    log = {df_2021_scaled.shape}\\n\"\n",
    "    f\"shape(df_2022) = {df_2022.shape},    log = {df_2022_scaled.shape}\\n\"\n",
    "    f\"shape(df_2023) = {df_2023.shape},    log = {df_2023_scaled.shape}\\n\"\n",
    "    f\"shape(df_2024) = {df_2024.shape},    log = {df_2024_scaled.shape}\\n\"\n",
    "    f\"shape(df_2025) = {df_2025.shape},    log = {df_2025_scaled.shape}\\n\"\n",
    "    f\"shape(df_full) = {df_full.shape},    log = {df_full_scaled.shape}\\n\"\n",
    ")"
   ],
   "id": "5ff8c0e022edb0c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(df_2020) = (253, 327),    log = (253, 327)\n",
      "shape(df_2021) = (252, 376),    log = (252, 376)\n",
      "shape(df_2022) = (251, 437),    log = (251, 437)\n",
      "shape(df_2023) = (250, 448),    log = (250, 448)\n",
      "shape(df_2024) = (252, 456),    log = (252, 456)\n",
      "shape(df_2025) = (228, 486),    log = (228, 486)\n",
      "shape(df_full) = (1486, 239),    log = (1486, 327)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:06:36.934897Z",
     "start_time": "2025-12-07T12:06:36.890582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transfer_entropy(X, Y, delay=1, gaussian_sigma=None):\n",
    "\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    Y = np.asarray(Y, dtype=float)\n",
    "\n",
    "    # Filtri\n",
    "    if not np.isfinite(X).all() or not np.isfinite(Y).all():\n",
    "        return 0.0\n",
    "\n",
    "    if len(X) <= delay or len(Y) <= delay:\n",
    "        return 0.0\n",
    "\n",
    "    X_t   = X[delay:]\n",
    "    X_tm1 = X[:-delay]\n",
    "    Y_tm1 = Y[:-delay]\n",
    "\n",
    "    if np.std(X_t) < 1e-12 or np.std(X_tm1) < 1e-12 or np.std(Y_tm1) < 1e-12:\n",
    "        return 0.0\n",
    "\n",
    "    n = float(len(X_t))\n",
    "    eps = 1e-12\n",
    "\n",
    "    # Bins\n",
    "    binX = min(20, max(4, int(np.sqrt(len(X)))))\n",
    "    binY = min(20, max(4, int(np.sqrt(len(Y)))))\n",
    "\n",
    "    pXYZ, _ = np.histogramdd(\n",
    "        np.vstack([X_t, Y_tm1, X_tm1]).T,\n",
    "        bins=[binX, binY, binX]\n",
    "    )\n",
    "    pXX, _ = np.histogramdd(np.vstack([X_t, X_tm1]).T, bins=[binX, binX])\n",
    "    pYX, _ = np.histogramdd(np.vstack([Y_tm1, X_tm1]).T, bins=[binY, binX])\n",
    "    pX,  _ = np.histogram(X_tm1, bins=binX)\n",
    "\n",
    "    pXYZ = pXYZ / n + eps\n",
    "    pXX  = pXX  / n + eps\n",
    "    pYX  = pYX  / n + eps\n",
    "    pX   = pX   / n + eps\n",
    "\n",
    "    if gaussian_sigma is not None:\n",
    "        sigma = min(gaussian_sigma, 0.8)\n",
    "        pXYZ = ndimage.gaussian_filter(pXYZ, sigma=sigma)\n",
    "        pXX  = ndimage.gaussian_filter(pXX,  sigma=sigma)\n",
    "        pYX  = ndimage.gaussian_filter(pYX,  sigma=sigma)\n",
    "        pX   = ndimage.gaussian_filter(pX,   sigma=sigma)\n",
    "\n",
    "    TE = 0.0\n",
    "    for i in range(binX):\n",
    "        for j in range(binY):\n",
    "            for k in range(binX):\n",
    "                TE += pXYZ[i,j,k] * np.log2((pXYZ[i,j,k] * pX[k]) /\n",
    "                                            (pXX[i,k] * pYX[j,k]))\n",
    "\n",
    "    return max(0.0, TE)\n",
    "\n",
    "def compute_te_matrix(df, delay=1, sigma=None):\n",
    "    cols = df.columns\n",
    "    n = len(cols)\n",
    "\n",
    "    A = np.zeros((n, n))\n",
    "    data = df.values\n",
    "\n",
    "    for i in tqdm(range(n), desc=\"Calculating TE Matrix\"):\n",
    "        Xi = data[:, i]\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            Yj = data[:, j]\n",
    "\n",
    "            A[i, j] = transfer_entropy(\n",
    "                Xi, Yj,\n",
    "                delay=delay,\n",
    "                gaussian_sigma=sigma\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(A, index=cols, columns=cols)\n",
    "\n",
    "def autocorr(x, lag=1):\n",
    "    return np.corrcoef(x[lag:], x[:-lag])[0,1]\n",
    "\n",
    "def compute_node_features(df):\n",
    "    features = {}\n",
    "    for col in df.columns:\n",
    "        x = df[col].values.astype(float)\n",
    "        feats = {\n",
    "            \"min\": np.min(x),\n",
    "            \"max\": np.max(x),\n",
    "            \"mean\": np.mean(x),\n",
    "            \"std\": np.std(x),\n",
    "            \"var\": np.var(x),\n",
    "            \"skew\": skew(x),\n",
    "            \"kurtosis\": kurtosis(x)\n",
    "        }\n",
    "        features[col] = feats\n",
    "    return pd.DataFrame(features).T\n",
    "\n",
    "def get_market_cap_only(tickers, sc_df):\n",
    "\n",
    "    features = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            row = sc_df.loc[sc_df[\"symbol\"] == ticker]\n",
    "\n",
    "            if not row.empty:\n",
    "                raw_cap = row.iloc[0].marketCap\n",
    "                clean_cap = float(str(raw_cap).replace(\",\", \"\").replace(\"$\", \"\"))\n",
    "\n",
    "                features[ticker] = {\n",
    "                    \"market_cap\": clean_cap\n",
    "                }\n",
    "            else:\n",
    "                features[ticker] = {\"market_cap\": 0}\n",
    "\n",
    "        except Exception as e:\n",
    "            features[ticker] = {\"market_cap\": 0}\n",
    "\n",
    "    return pd.DataFrame(features).T\n",
    "\n",
    "def get_node_sizes(nodes_list, node_features, min_size=50, max_size=400):\n",
    "    caps = node_features.loc[nodes_list, \"market_cap\"].values.astype(float)\n",
    "\n",
    "    positive_caps = caps[caps > 0]\n",
    "    if len(positive_caps) == 0:\n",
    "        positive_caps = np.array([1.0])\n",
    "\n",
    "    min_positive = positive_caps.min()\n",
    "    caps = np.where(caps > 0, caps, min_positive)\n",
    "\n",
    "    caps = np.log(caps).reshape(-1, 1)\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(min_size, max_size))\n",
    "    sizes = scaler.fit_transform(caps).flatten()\n",
    "\n",
    "    return sizes\n",
    "\n",
    "def build_graph(A, X):\n",
    "    A = A.values\n",
    "    n = A.shape[0]\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if A[i,j]!=0 and i!=j:\n",
    "                edge_index.append([i,j])\n",
    "                edge_attr.append([A[i,j]])\n",
    "\n",
    "    return torch.tensor(X.values, dtype=torch.float), \\\n",
    "           torch.tensor(edge_index, dtype=torch.long).T, \\\n",
    "           torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "def compute_all_metrics(G):\n",
    "    in_deg = dict(G.in_degree(weight=None))\n",
    "    out_deg = dict(G.out_degree(weight=None))\n",
    "    in_deg_w = dict(G.in_degree(weight=\"weight\"))\n",
    "    out_deg_w = dict(G.out_degree(weight=\"weight\"))\n",
    "    total_deg = {n: in_deg[n]+out_deg[n] for n in G.nodes()}\n",
    "    total_deg_w = {n: in_deg_w[n]+out_deg_w[n] for n in G.nodes()}\n",
    "    pagerank = nx.pagerank(G, weight=\"weight\")\n",
    "    hubs, auth = nx.hits(G)\n",
    "    bet = nx.betweenness_centrality(G, weight=\"weight\")\n",
    "    clo = nx.closeness_centrality(G, distance=lambda u,v,d: 1/d[\"weight\"])\n",
    "    try:\n",
    "        eig = nx.eigenvector_centrality_numpy(G, weight=\"weight\")\n",
    "    except nx.AmbiguousSolution:\n",
    "        eig = nx.eigenvector_centrality(G, weight=\"weight\", max_iter=500)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"in_degree\": in_deg, \"out_degree\": out_deg, \"total_degree\": total_deg,\n",
    "        \"in_degree_w\": in_deg_w, \"out_degree_w\": out_deg_w, \"total_degree_w\": total_deg_w,\n",
    "        \"pagerank\": pagerank, \"hub\": hubs, \"authority\": auth,\n",
    "        \"betweenness\": bet, \"closeness\": clo, \"eigenvector\": eig\n",
    "    })\n",
    "    return df.sort_values(\"pagerank\", ascending=False)\n",
    "\n",
    "def plot_te_graph(G, cluster_labels, node_features, figsize=(10,8), seed=42, save_path=None):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    pos = nx.spring_layout(G, seed=seed, k=0.15)\n",
    "\n",
    "    cluster_dict = cluster_labels.to_dict()\n",
    "    node_colors = [cluster_dict.get(node, -1) for node in G.nodes()]\n",
    "    unique_clusters = sorted(list(set(node_colors)))\n",
    "    n_clusters = len(unique_clusters)\n",
    "    base_cmap = plt.colormaps['tab20'].resampled(n_clusters)\n",
    "    cluster_cmap = ListedColormap(base_cmap.colors[:n_clusters])\n",
    "\n",
    "    node_sizes = get_node_sizes(list(G.nodes()), node_features, min_size=50, max_size=800)\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_size=node_sizes,\n",
    "        node_color=node_colors,\n",
    "        cmap=cluster_cmap,\n",
    "        edgecolors='black',\n",
    "        linewidths=0.5,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "\n",
    "    weights = [d['weight'] for u, v, d in G.edges(data=True)]\n",
    "    if len(weights) > 0:\n",
    "        norm = Normalize(vmin=min(weights), vmax=max(weights))\n",
    "\n",
    "        nx.draw_networkx_edges(\n",
    "            G, pos,\n",
    "            arrowstyle=\"-|>\",\n",
    "            arrowsize=10,\n",
    "            width=[0.5 + 2*(w - min(weights)) / (max(weights) - min(weights)) for w in weights],\n",
    "            edge_color=weights,\n",
    "            edge_cmap=plt.cm.plasma_r,   # OBRNJENA KOLORNA MAPA\n",
    "            edge_vmin=min(weights),\n",
    "            edge_vmax=max(weights),\n",
    "            alpha=0.65,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.plasma_r, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)\n",
    "        cbar.set_label(\"Transfer Entropy Weight\")\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos, font_size=6, font_weight=\"bold\", ax=ax)\n",
    "\n",
    "    ax.set_title(\"TE Graph – Size by Market Cap\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        fig.savefig(os.path.join(save_path, \"te_graph_marketcap.png\"),\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def scale_features(node_features):\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(node_features.values)\n",
    "    return pd.DataFrame(scaled, index=node_features.index, columns=node_features.columns)\n",
    "\n",
    "def build_knn_graph(node_features, k=5):\n",
    "    X = node_features.values\n",
    "    tickers = node_features.index.tolist()\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    G_knn = nx.Graph()\n",
    "    G_knn.add_nodes_from(tickers)\n",
    "    for i, neigh_list in enumerate(indices):\n",
    "        for j in neigh_list[1:]:\n",
    "            G_knn.add_edge(tickers[i], tickers[j], weight=np.linalg.norm(X[i]-X[j]))\n",
    "    return G_knn\n",
    "\n",
    "def run_dbscan(node_features, eps=0.5, min_samples=5):\n",
    "    X = node_features.values\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = model.fit_predict(X)\n",
    "\n",
    "    clusters = pd.Series(labels, index=node_features.index, name=\"dbscan_cluster\")\n",
    "\n",
    "    return clusters, model\n",
    "\n",
    "def run_hdbscan(node_features, min_cluster_size=5, min_samples=None):\n",
    "    X = node_features.values\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples,\n",
    "        metric='euclidean'\n",
    "    )\n",
    "    labels = clusterer.fit_predict(X)\n",
    "\n",
    "    clusters = pd.Series(labels, index=node_features.index, name=\"hdbscan_cluster\")\n",
    "\n",
    "    return clusters, clusterer\n",
    "\n",
    "def run_kmeans(node_features, n_clusters=5, random_state=42):\n",
    "    X = node_features.values\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    labels = model.fit_predict(X)\n",
    "\n",
    "    score = silhouette_score(X, labels)\n",
    "\n",
    "    clusters = pd.Series(labels, index=node_features.index, name=\"kmeans_cluster\")\n",
    "\n",
    "    return clusters, model, score\n",
    "\n",
    "def plot_knn_with_clusters(\n",
    "    G_knn,\n",
    "    cluster_labels,\n",
    "    node_features,\n",
    "    title=\"KNN Graph Colored by Clusters\",\n",
    "    figsize=(10, 8),\n",
    "    seed=42,\n",
    "    save_path=None\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    pos = nx.spring_layout(G_knn, seed=seed, k=0.15)\n",
    "\n",
    "    cluster_dict = cluster_labels.to_dict()\n",
    "    node_colors = [cluster_dict.get(n, -1) for n in G_knn.nodes()]\n",
    "    unique_clusters = sorted(set(node_colors))\n",
    "\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", len(unique_clusters))\n",
    "\n",
    "    node_sizes = get_node_sizes(\n",
    "        list(G_knn.nodes()),\n",
    "        node_features,\n",
    "        min_size=40,\n",
    "        max_size=700\n",
    "    )\n",
    "\n",
    "    nx.draw_networkx_edges(\n",
    "        G_knn, pos,\n",
    "        alpha=0.15,\n",
    "        edge_color='gray',\n",
    "        width=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        G_knn, pos,\n",
    "        node_size=node_sizes,\n",
    "        node_color=node_colors,\n",
    "        cmap=cmap,\n",
    "        linewidths=0.4,\n",
    "        edgecolors='black',\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    for (node, (x, y), size) in zip(G_knn.nodes(), pos.values(), node_sizes):\n",
    "        if size > np.percentile(node_sizes, 80):  # top 20% po velikosti\n",
    "            ax.text(\n",
    "                x, y, node,\n",
    "                fontsize=7,\n",
    "                fontweight=\"bold\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\"\n",
    "            )\n",
    "\n",
    "    for c in unique_clusters:\n",
    "        ax.scatter([], [], c=cmap(unique_clusters.index(c)), label=f\"Cluster {c}\")\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper left\",\n",
    "        fontsize=8,\n",
    "        frameon=True,\n",
    "        facecolor='white',\n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{title} (Node Size = Market Cap)\", fontsize=12, fontweight='bold')\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        fig.savefig(\n",
    "            os.path.join(save_path, \"knn_clusters_marketcap.png\"),\n",
    "            dpi=300,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_results_table(results, save_path=None):\n",
    "    fig, ax = plt.subplots(figsize=(15,6))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=results[\"metrics\"].round(3).values,\n",
    "                     colLabels=results[\"metrics\"].columns,\n",
    "                     rowLabels=results[\"metrics\"].index,\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    table.scale(1, 1.5)\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        fig.savefig(os.path.join(save_path, \"results_table.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_per_metric(metrics_df, n=5, n_cols=3, save_path=None, csv_path=None):\n",
    "    metrics = metrics_df.columns\n",
    "    n_metrics = len(metrics)\n",
    "    n_rows = math.ceil(n_metrics / n_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3.8 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # zbiranje top-n v tabelo\n",
    "    rows_for_csv = []\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "\n",
    "        top_nodes = metrics_df[metric].nlargest(n).reset_index()\n",
    "        top_nodes.columns = [\"node\", \"value\"]\n",
    "\n",
    "        # dodaj rank za CSV\n",
    "        top_nodes[\"rank\"] = top_nodes[\"value\"].rank(ascending=False, method=\"first\").astype(int)\n",
    "        top_nodes[\"metric\"] = metric\n",
    "\n",
    "        # shrani v zbirnik\n",
    "        rows_for_csv.append(top_nodes)\n",
    "\n",
    "        color = sns.color_palette(\"viridis\", 8)[3]\n",
    "\n",
    "        sns.barplot(\n",
    "            data=top_nodes,\n",
    "            x=\"value\",\n",
    "            y=\"node\",\n",
    "            color=color,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Top {n} Nodes by {metric}\", fontsize=11, fontweight=\"bold\")\n",
    "        ax.set_xlabel(metric, fontsize=10)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "        ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "        ax.tick_params(axis='y', labelsize=9)\n",
    "        ax.tick_params(axis='x', labelsize=8)\n",
    "\n",
    "    # onemogoči prazne grafe\n",
    "    for j in range(len(metrics), len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # shrani sliko\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        fig.savefig(\n",
    "            os.path.join(save_path, \"top_per_metric.png\"),\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    # shrani CSV z top-N metriko\n",
    "    if csv_path is not None:\n",
    "        os.makedirs(csv_path, exist_ok=True)\n",
    "        final_df = pd.concat(rows_for_csv, ignore_index=True)\n",
    "        final_df.to_csv(\n",
    "            os.path.join(csv_path, \"top_per_metric.csv\"),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def run_umap(\n",
    "    node_features,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    metric=\"euclidean\",\n",
    "    random_state=42\n",
    "):\n",
    "\n",
    "    X = node_features.values\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric=metric,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    embedding = reducer.fit_transform(X)\n",
    "\n",
    "    cols = [f\"UMAP_{i+1}\" for i in range(n_components)]\n",
    "    umap_df = pd.DataFrame(embedding, index=node_features.index, columns=cols)\n",
    "\n",
    "    return umap_df, reducer\n",
    "\n",
    "def plot_umap(\n",
    "    umap_df,\n",
    "    node_features,\n",
    "    cluster_labels=None,\n",
    "    figsize=(10, 8),\n",
    "    title=\"UMAP Projection\",\n",
    "    save_path=None,\n",
    "    suffix=\"default\"\n",
    "):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "\n",
    "    if cluster_labels is not None:\n",
    "        cluster_dict = cluster_labels.to_dict()\n",
    "        labels = np.array([cluster_dict.get(node, -1) for node in umap_df.index])\n",
    "\n",
    "        unique_labels = sorted(np.unique(labels))\n",
    "        n_labels = len(unique_labels)\n",
    "\n",
    "        palette = sns.color_palette(\"tab20\", n_colors=n_labels)\n",
    "        color_map = {lbl: palette[i] for i, lbl in enumerate(unique_labels)}\n",
    "\n",
    "        if -1 in unique_labels:\n",
    "            color_map[-1] = (0.6, 0.6, 0.6)\n",
    "\n",
    "        colors = [color_map[lbl] for lbl in labels]\n",
    "    else:\n",
    "        colors = \"gray\"\n",
    "        labels = None\n",
    "\n",
    "    sizes = get_node_sizes(\n",
    "        umap_df.index,\n",
    "        node_features,\n",
    "        min_size=40,\n",
    "        max_size=600\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        umap_df.iloc[:, 0],\n",
    "        umap_df.iloc[:, 1],\n",
    "        c=colors,\n",
    "        s=sizes,\n",
    "        alpha=0.75,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2\n",
    "    )\n",
    "\n",
    "    size_threshold = np.percentile(sizes, 85)\n",
    "    for idx, (x, y) in enumerate(zip(umap_df.iloc[:, 0], umap_df.iloc[:, 1])):\n",
    "        if sizes[idx] >= size_threshold:\n",
    "            plt.text(\n",
    "                x, y,\n",
    "                umap_df.index[idx],\n",
    "                fontsize=7,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontweight=\"bold\"\n",
    "            )\n",
    "\n",
    "    if cluster_labels is not None:\n",
    "        legend_elements = []\n",
    "        for lbl in unique_labels:\n",
    "            legend_elements.append(\n",
    "                plt.Line2D(\n",
    "                    [0], [0],\n",
    "                    marker='o',\n",
    "                    color='w',\n",
    "                    label=f\"Cluster {lbl}\",\n",
    "                    markersize=8,\n",
    "                    markerfacecolor=color_map[lbl],\n",
    "                    markeredgecolor='black',\n",
    "                    markeredgewidth=0.3\n",
    "                )\n",
    "            )\n",
    "        plt.legend(\n",
    "            handles=legend_elements,\n",
    "            title=\"Clusters\",\n",
    "            loc=\"upper right\",\n",
    "            fontsize=8,\n",
    "            frameon=True\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"UMAP 1\", fontsize=11)\n",
    "    plt.ylabel(\"UMAP 2\", fontsize=11)\n",
    "    plt.title(f\"{title} (Size = Market Cap)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    plt.grid(False)\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        plt.savefig(\n",
    "            os.path.join(save_path, f\"umap_{suffix}.png\"),\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_graph_metrics_distribution(results, n_cols=2, save_path=None):\n",
    "    df = results[\"metrics\"]\n",
    "    metrics_names = df.columns\n",
    "    n_metrics = len(metrics_names)\n",
    "    n_rows = math.ceil(n_metrics / n_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4.5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    hist_color = sns.color_palette(\"Blues\", 6)[3]\n",
    "    kde_color = sns.color_palette(\"Reds\", 6)[4]\n",
    "\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        ax = axes[i]\n",
    "        data = df[metric].dropna()\n",
    "\n",
    "        # Histogram\n",
    "        sns.histplot(\n",
    "            data,\n",
    "            ax=ax,\n",
    "            bins=30,\n",
    "            color=hist_color,\n",
    "            kde=False,\n",
    "            edgecolor=\"black\",\n",
    "            alpha=0.75\n",
    "        )\n",
    "\n",
    "        # KDE\n",
    "        sns.kdeplot(\n",
    "            data,\n",
    "            ax=ax,\n",
    "            color=kde_color,\n",
    "            linewidth=2\n",
    "        )\n",
    "\n",
    "        mean_val = data.mean()\n",
    "        median_val = data.median()\n",
    "\n",
    "        ax.axvline(\n",
    "            mean_val,\n",
    "            color=\"red\",\n",
    "            linestyle=\"dashed\",\n",
    "            linewidth=1,\n",
    "            label=f\"Mean = {mean_val:.3f}\"\n",
    "        )\n",
    "        ax.axvline(\n",
    "            median_val,\n",
    "            color=\"black\",\n",
    "            linestyle=\"dotted\",\n",
    "            linewidth=1,\n",
    "            label=f\"Median = {median_val:.3f}\"\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Porazdelitev metrike: {metric}\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Vrednost\", fontsize=10)\n",
    "        ax.set_ylabel(\"Frekvenca\", fontsize=10)\n",
    "\n",
    "        ax.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.35)\n",
    "\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path is not None:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        fig.savefig(\n",
    "            os.path.join(save_path, \"graph_metrics_distribution.png\"),\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def dynamic_te_threshold(A):\n",
    "    vals = A.values.flatten()\n",
    "    vals = vals[vals > 0]\n",
    "\n",
    "    soft = np.nanpercentile(vals, 80)\n",
    "    medium = vals.mean()\n",
    "    hard = np.nanpercentile(vals, 95)\n",
    "\n",
    "    return {\"soft\": soft, \"medium\": medium, \"hard\": hard}"
   ],
   "id": "fe1aba28fc9e7799",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:06:39.224185Z",
     "start_time": "2025-12-07T12:06:39.210082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_full_pipeline(\n",
    "        df,\n",
    "        sc,\n",
    "        delay=30,\n",
    "        sigma=0.75,\n",
    "        te_threshold_=\"medium\",\n",
    "        knn_k=10,\n",
    "        dbscan_eps=1.2,\n",
    "        dbscan_min=5,\n",
    "        kmeans_n=12,\n",
    "        topk=3,\n",
    "        plot_top_n=5,\n",
    "        umap_n_neighbors=20,\n",
    "        umap_min_dist=0.25,\n",
    "        min_hdbscan_cluster=6,\n",
    "        metric=\"euclidean\"\n",
    "):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 0) Folder\n",
    "    # -------------------------------------------------------\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    years = sorted(df.index.year.unique())\n",
    "    folder = str(years[0]) if len(years) == 1 else \"FULL\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(\"Folder:\", folder)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1) Market Cap\n",
    "    # -------------------------------------------------------\n",
    "    market_cap_features = get_market_cap_only(df.columns, sc)\n",
    "    results[\"market_cap\"] = market_cap_features\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2) Node features\n",
    "    # -------------------------------------------------------\n",
    "    node_features = compute_node_features(df)\n",
    "    results[\"node_features\"] = node_features\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 3) TE matrix\n",
    "    # -------------------------------------------------------\n",
    "    adj_path = os.path.join(folder, \"A.csv\")\n",
    "\n",
    "    if os.path.exists(adj_path):\n",
    "        A = pd.read_csv(adj_path, index_col=0)\n",
    "        print(\"Loaded TE matrix:\", A.shape)\n",
    "    else:\n",
    "        A = compute_te_matrix(df, delay=delay, sigma=sigma)\n",
    "        A.to_csv(adj_path)\n",
    "        print(\"Computed TE matrix:\", A.shape)\n",
    "\n",
    "    results[\"A_raw\"] = A\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 4) Threshold / top-k\n",
    "    # -------------------------------------------------------\n",
    "\n",
    "    thr_dict = dynamic_te_threshold(A)\n",
    "    te_threshold_value = thr_dict[te_threshold_]\n",
    "\n",
    "    print(f\"TE threshold ({te_threshold_}): {te_threshold_value:.6f}\")\n",
    "\n",
    "    A_thr = A.where(A >= te_threshold_value, 0)\n",
    "\n",
    "    if topk is not None:\n",
    "        for row in A_thr.index:\n",
    "            topk_idx = A_thr.loc[row].nlargest(topk).index\n",
    "            A_thr.loc[row] = 0\n",
    "            A_thr.loc[row, topk_idx] = A.loc[row, topk_idx]\n",
    "\n",
    "    max_val = A_thr.values.max() if A_thr.values.max() > 0 else 1\n",
    "    A_scaled = A_thr / max_val\n",
    "    results[\"A_thr\"] = A_scaled\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 5) Directed TE graph\n",
    "    # -------------------------------------------------------\n",
    "    G = nx.from_pandas_adjacency(A_scaled, create_using=nx.DiGraph)\n",
    "    G.remove_edges_from((u, v) for u, v, d in G.edges(data=True) if d[\"weight\"] == 0)\n",
    "    results[\"G\"] = G\n",
    "\n",
    "    print(f\"TE graph: nodes={G.number_of_nodes()}, edges={G.number_of_edges()}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 6) Graph metrics\n",
    "    # -------------------------------------------------------\n",
    "    df_metrics = compute_all_metrics(G)\n",
    "    results[\"metrics\"] = df_metrics\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 7) Scaling for feature-space clustering\n",
    "    # -------------------------------------------------------\n",
    "    scaled_features = scale_features(node_features)\n",
    "    results[\"scaled_features\"] = scaled_features\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 8) KNN graph\n",
    "    # -------------------------------------------------------\n",
    "    G_knn = build_knn_graph(scaled_features, k=knn_k)\n",
    "    results[\"G_knn\"] = G_knn\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 9) DBSCAN / HDBSCAN / KMeans\n",
    "    # -------------------------------------------------------\n",
    "    db_labels, _ = run_dbscan(scaled_features, eps=dbscan_eps, min_samples=dbscan_min)\n",
    "    hdb_labels, hdb_model = run_hdbscan(scaled_features, min_cluster_size=min_hdbscan_cluster)\n",
    "    kmeans_labels, kmeans_model, k_sil = run_kmeans(scaled_features, n_clusters=kmeans_n)\n",
    "\n",
    "    results[\"dbscan_labels\"] = db_labels\n",
    "    results[\"hdbscan_labels\"] = hdb_labels\n",
    "    results[\"kmeans_labels\"] = kmeans_labels\n",
    "    results[\"kmeans_model\"] = kmeans_model\n",
    "    results[\"kmeans_silhouette\"] = k_sil\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 10) UMAP embedding\n",
    "    # -------------------------------------------------------\n",
    "    umap_df, umap_model = run_umap(\n",
    "        scaled_features,\n",
    "        n_neighbors=umap_n_neighbors,\n",
    "        min_dist=umap_min_dist,\n",
    "        metric=metric\n",
    "    )\n",
    "\n",
    "    results[\"umap_df\"] = umap_df\n",
    "    results[\"umap_model\"] = umap_model\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 11) Plots\n",
    "    # -------------------------------------------------------\n",
    "    plot_umap(umap_df, market_cap_features, db_labels,\n",
    "              save_path=folder, title=\"UMAP + DBSCAN\", suffix=\"dbscan\")\n",
    "\n",
    "    plot_umap(umap_df, market_cap_features, hdb_labels,\n",
    "              save_path=folder, title=\"UMAP + HDBSCAN\", suffix=\"hdbscan\")\n",
    "\n",
    "    plot_umap(umap_df, market_cap_features, kmeans_labels,\n",
    "              save_path=folder, title=\"UMAP + KMeans\", suffix=\"kmeans\")\n",
    "\n",
    "    plot_te_graph(G, db_labels, node_features=market_cap_features, save_path=folder)\n",
    "\n",
    "    plot_knn_with_clusters(G_knn, db_labels, node_features=market_cap_features,\n",
    "                           save_path=folder, title=\"KNN + DBSCAN\")\n",
    "\n",
    "    plot_knn_with_clusters(G_knn, kmeans_labels, node_features=market_cap_features,\n",
    "                           save_path=folder, title=\"KNN + KMeans\")\n",
    "\n",
    "    plot_top_per_metric(df_metrics, n=plot_top_n, n_cols=4, save_path=folder, csv_path=folder)\n",
    "\n",
    "    plot_graph_metrics_distribution(results, n_cols=2, save_path=folder)\n",
    "    plot_results_table({\"metrics\": df_metrics}, save_path=folder)\n",
    "\n",
    "    return results"
   ],
   "id": "3358dba2792e12fa",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = run_full_pipeline(\n",
    "    df=df_2025_scaled,\n",
    "    sc=sc,\n",
    "    delay=2,\n",
    "    sigma=0.45,\n",
    "    te_threshold_=\"hard\",\n",
    "    topk=4,\n",
    "    knn_k=10,\n",
    "    dbscan_eps=0.44,\n",
    "    dbscan_min=3,\n",
    "    min_hdbscan_cluster=3,\n",
    "    metric=\"correlation\",\n",
    "    kmeans_n=5,\n",
    "    umap_n_neighbors=12,\n",
    "    umap_min_dist=0.15,\n",
    "    plot_top_n=5\n",
    ")"
   ],
   "id": "1ab78846e723d6e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dfs = [df_2020_scaled, df_2021_scaled, df_2022_scaled, df_2023_scaled, df_2024_scaled, df_2025_scaled, df_full_scaled]\n",
    "\n",
    "for df in dfs:\n",
    "    results = run_full_pipeline(\n",
    "    df=df,\n",
    "    sc=sc,\n",
    "    delay=2,\n",
    "    sigma=0.45,\n",
    "    te_threshold_=\"hard\",\n",
    "    topk=4,\n",
    "    knn_k=10,\n",
    "    dbscan_eps=0.44,\n",
    "    dbscan_min=3,\n",
    "    min_hdbscan_cluster=3,\n",
    "    metric=\"correlation\",\n",
    "    kmeans_n=5,\n",
    "    umap_n_neighbors=12,\n",
    "    umap_min_dist=0.15,\n",
    "    plot_top_n=5\n",
    "    )"
   ],
   "id": "40c8b7efd42f8598",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:33:39.038113Z",
     "start_time": "2025-12-07T12:33:18.472738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT = \".\"\n",
    "SAVE_DIR = os.path.join(ROOT, \"temporal\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "years = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\", \"2025\"]\n",
    "\n",
    "image_types = [\n",
    "    \"knn_clusters_marketcap.png\",\n",
    "    \"umap_hdbscan.png\",\n",
    "    \"umap_kmeans.png\",\n",
    "    \"umap_dbscan.png\",\n",
    "    \"te_graph_marketcap.png\",\n",
    "    \"top_per_metric.png\",\n",
    "    \"graph_metrics_distribution.png\"\n",
    "]\n",
    "\n",
    "for img_name in image_types:\n",
    "    loaded = []\n",
    "\n",
    "    if img_name == \"top_per_metric.png\":\n",
    "        cols = 4\n",
    "    else:\n",
    "        cols = 3\n",
    "\n",
    "    for year in years:\n",
    "        folder = os.path.join(ROOT, year)\n",
    "        path = os.path.join(folder, img_name)\n",
    "        if os.path.exists(path):\n",
    "            loaded.append((year, Image.open(path)))\n",
    "\n",
    "    if len(loaded) == 0:\n",
    "        continue\n",
    "\n",
    "    rows = (len(loaded) + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4.5, rows * 3.8))\n",
    "\n",
    "    if rows == 1 and cols == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for ax, (year, img) in zip(axes, loaded):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(year, fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for ax in axes[len(loaded):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        left=0.01, right=0.99, top=0.97, bottom=0.03,\n",
    "        wspace=0.05, hspace=0.05\n",
    "    )\n",
    "\n",
    "    out_path = os.path.join(SAVE_DIR, f\"temporal_{img_name}\")\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Shranjeno: {out_path}\")"
   ],
   "id": "56565016de98b3fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shranjeno: ./temporal/temporal_knn_clusters_marketcap.png\n",
      "Shranjeno: ./temporal/temporal_umap_hdbscan.png\n",
      "Shranjeno: ./temporal/temporal_umap_kmeans.png\n",
      "Shranjeno: ./temporal/temporal_umap_dbscan.png\n",
      "Shranjeno: ./temporal/temporal_te_graph_marketcap.png\n",
      "Shranjeno: ./temporal/temporal_top_per_metric.png\n",
      "Shranjeno: ./temporal/temporal_graph_metrics_distribution.png\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:35:56.027352Z",
     "start_time": "2025-12-07T12:35:56.004983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# ============================================\n",
    "# 1) Load\n",
    "# ============================================\n",
    "\n",
    "def load_top5_all_years(base_folder, years):\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        folder = os.path.join(base_folder, year)\n",
    "        file_path = os.path.join(folder, \"top_per_metric.csv\")\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                names=[\"node\", \"value\", \"rank\", \"metric\"],\n",
    "                dtype={\"node\": str, \"metric\": str}\n",
    "            )\n",
    "            df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "            df[\"rank\"] = pd.to_numeric(df[\"rank\"], errors=\"coerce\")\n",
    "            df[\"year\"] = year\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            print(f\"Manjka datoteka: {file_path}\")\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2) RANK EVOLUTION – s stabilnimi nodi\n",
    "# ============================================\n",
    "\n",
    "def plot_rank_evolution(df, save_dir, min_years=3):\n",
    "\n",
    "    metrics = df[\"metric\"].unique()\n",
    "    year_order = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\", \"2025\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "\n",
    "        sub = df[df[\"metric\"] == metric]\n",
    "\n",
    "        # Izberi node, ki se pojavijo vsaj v min_years letih\n",
    "        stable_nodes = sub[\"node\"].value_counts()\n",
    "        stable_nodes = stable_nodes[stable_nodes >= min_years].index\n",
    "\n",
    "        sub = sub[sub[\"node\"].isin(stable_nodes)]\n",
    "\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        pivot = sub.pivot_table(\n",
    "            index=\"node\",\n",
    "            columns=\"year\",\n",
    "            values=\"rank\",\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "\n",
    "        # sortiraj stolpce po pravem vrstnem redu\n",
    "        pivot = pivot[[y for y in year_order if y in pivot.columns]]\n",
    "\n",
    "        if pivot.empty:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "        for node in pivot.index:\n",
    "            plt.plot(\n",
    "                pivot.columns,\n",
    "                pivot.loc[node],\n",
    "                marker=\"o\",\n",
    "                linewidth=2,\n",
    "                label=node\n",
    "            )\n",
    "\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title(f\"Rank Evolution (Stable Nodes ≥ {min_years} Years) – {metric}\", fontsize=18)\n",
    "        plt.xlabel(\"Leto\", fontsize=14)\n",
    "        plt.ylabel(\"Rank (1 najboljši)\", fontsize=14)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.legend(title=\"Node\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(save_dir, f\"rank_evolution_filtered_{metric}.png\"),\n",
    "            dpi=200, bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3) HEATMAP vrednosti\n",
    "# ============================================\n",
    "\n",
    "def plot_value_heatmap(df, save_dir):\n",
    "\n",
    "    metrics = df[\"metric\"].unique()\n",
    "    year_order = [\"2020\",\"2021\",\"2022\",\"2023\",\"2024\",\"2025\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "\n",
    "        sub = df[df[\"metric\"] == metric]\n",
    "\n",
    "        pivot = sub.pivot_table(\n",
    "            index=\"node\",\n",
    "            columns=\"year\",\n",
    "            values=\"value\",\n",
    "            aggfunc=\"first\"\n",
    "        )\n",
    "\n",
    "        pivot = pivot[[y for y in year_order if y in pivot.columns]]\n",
    "\n",
    "        if pivot.empty or pivot.isna().all().all():\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "        plt.title(f\"Metric Values Through Years – {metric}\", fontsize=16)\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(save_dir, f\"value_heatmap_{metric}.png\"),\n",
    "            dpi=200, bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4) JACCARD matrika\n",
    "# ============================================\n",
    "\n",
    "def plot_jaccard(df, save_dir):\n",
    "\n",
    "    metrics = df[\"metric\"].unique()\n",
    "    years = [\"2020\",\"2021\",\"2022\",\"2023\",\"2024\",\"2025\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "\n",
    "        sub = df[df[\"metric\"] == metric]\n",
    "\n",
    "        jac = pd.DataFrame(index=years, columns=years, dtype=float)\n",
    "\n",
    "        for y1 in years:\n",
    "            s1 = set(sub[sub[\"year\"] == y1][\"node\"])\n",
    "            for y2 in years:\n",
    "                s2 = set(sub[sub[\"year\"] == y2][\"node\"])\n",
    "                if len(s1 | s2) == 0:\n",
    "                    jac.loc[y1, y2] = None\n",
    "                else:\n",
    "                    jac.loc[y1, y2] = len(s1 & s2) / len(s1 | s2)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(jac.astype(float), annot=True, cmap=\"Blues\", vmin=0, vmax=1)\n",
    "        plt.title(f\"Jaccard Similarity – {metric}\", fontsize=16)\n",
    "\n",
    "        plt.savefig(\n",
    "            os.path.join(save_dir, f\"jaccard_{metric}.png\"),\n",
    "            dpi=200, bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5) FREQUENCY\n",
    "# ============================================\n",
    "\n",
    "def plot_frequency(df, save_dir, top_n=20):\n",
    "\n",
    "    freq = df[\"node\"].value_counts().head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    sns.barplot(x=freq.values, y=freq.index, palette=\"viridis\")\n",
    "    plt.title(f\"Top {top_n} Most Frequent Top-5 Nodes\", fontsize=16)\n",
    "    plt.xlabel(\"Frekvenca\", fontsize=14)\n",
    "    plt.ylabel(\"Node\", fontsize=14)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(save_dir, f\"top_frequency_top{top_n}.png\"),\n",
    "        dpi=200, bbox_inches=\"tight\"\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 6) MASTER\n",
    "# ============================================\n",
    "\n",
    "def make_all_plots(base_folder=\".\", save_folder=\"top5_results\"):\n",
    "\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    years = [\"2020\",\"2021\",\"2022\",\"2023\",\"2024\",\"2025\"]\n",
    "    df = load_top5_all_years(base_folder, years)\n",
    "\n",
    "    plot_rank_evolution(df, save_folder)\n",
    "    plot_value_heatmap(df, save_folder)\n",
    "    plot_jaccard(df, save_folder)\n",
    "    plot_frequency(df, save_folder)\n",
    "\n",
    "    print(\"Vsi grafi shranjeni v:\", save_folder)"
   ],
   "id": "7622eeb261e95105",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:36:01.724635Z",
     "start_time": "2025-12-07T12:35:57.738073Z"
    }
   },
   "cell_type": "code",
   "source": "make_all_plots(\".\")",
   "id": "6f800711a620828a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vsi grafi shranjeni v: top5_results\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T12:39:40.491220Z",
     "start_time": "2025-12-07T12:39:40.464586Z"
    }
   },
   "cell_type": "code",
   "source": "sc[ sc[\"symbol\"].isin([\"ABBV\", \"ABEO\", \"ABSI\", \"ABT\"]) ]",
   "id": "ec22a0c484a598f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    symbol                                   name lastsale netchange  \\\n",
       "2     ABBV               AbbVie Inc. Common Stock  $226.08     -2.63   \n",
       "6      ABT       Abbott Laboratories Common Stock  $125.08     -0.32   \n",
       "350   ABSI         Absci Corporation Common Stock    $3.58     -0.15   \n",
       "429   ABEO  Abeona Therapeutics Inc. Common Stock    $4.87      UNCH   \n",
       "\n",
       "    pctchange        marketCap                           url  \n",
       "2      -1.15%  399,570,317,603  /market-activity/stocks/abbv  \n",
       "6     -0.255%  217,498,103,131   /market-activity/stocks/abt  \n",
       "350   -4.021%      538,330,081  /market-activity/stocks/absi  \n",
       "429        --      263,911,928  /market-activity/stocks/abeo  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>lastsale</th>\n",
       "      <th>netchange</th>\n",
       "      <th>pctchange</th>\n",
       "      <th>marketCap</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc. Common Stock</td>\n",
       "      <td>$226.08</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>-1.15%</td>\n",
       "      <td>399,570,317,603</td>\n",
       "      <td>/market-activity/stocks/abbv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories Common Stock</td>\n",
       "      <td>$125.08</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.255%</td>\n",
       "      <td>217,498,103,131</td>\n",
       "      <td>/market-activity/stocks/abt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>ABSI</td>\n",
       "      <td>Absci Corporation Common Stock</td>\n",
       "      <td>$3.58</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-4.021%</td>\n",
       "      <td>538,330,081</td>\n",
       "      <td>/market-activity/stocks/absi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>ABEO</td>\n",
       "      <td>Abeona Therapeutics Inc. Common Stock</td>\n",
       "      <td>$4.87</td>\n",
       "      <td>UNCH</td>\n",
       "      <td>--</td>\n",
       "      <td>263,911,928</td>\n",
       "      <td>/market-activity/stocks/abeo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
